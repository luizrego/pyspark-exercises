{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize PySpark\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark SQL Session\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|color|fruit| size|\n",
      "+-----+-----+-----+\n",
      "|  Red|Apple|Large|\n",
      "+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example simple JSON file\n",
    "df = spark.read.json(\"example_1.json\", multiLine=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(color,StringType,true),StructField(fruit,StringType,true),StructField(size,StringType,true)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|color|\n",
      "+-----+\n",
      "|  Red|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"color\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- color: string (nullable = true)\n",
      " |-- fruit: string (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) FileScan json [color#0,fruit#1,size#2] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/Users/lrego/Projects/py-projects/pyspark-exercise/map_reduce_examples/exa..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<color:string,fruit:string,size:string>\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested JSON structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform data analysis in a nested JSON structure.\n",
    "\n",
    "https://docs.azuredatabricks.net/_static/notebooks/transform-complex-data-types-python.html  \n",
    "https://sparkbyexamples.com/spark/spark-sql-structtype-on-dataframe/  \n",
    "https://stackoverflow.com/questions/37471346/automatically-and-elegantly-flatten-dataframe-in-spark-sql\n",
    "https://adatis.co.uk/parsing-nested-json-lists-in-databricks-using-python/  \n",
    "https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html  \n",
    "https://stackoverflow.com/questions/34271398/flatten-nested-spark-dataframe\n",
    "https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html\n",
    "\n",
    "This is a unformatted json example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.json(\"example_2.json\", multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- quiz: struct (nullable = true)\n",
      " |    |-- maths: struct (nullable = true)\n",
      " |    |    |-- q1: struct (nullable = true)\n",
      " |    |    |    |-- answer: string (nullable = true)\n",
      " |    |    |    |-- options: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- question: string (nullable = true)\n",
      " |    |    |-- q2: struct (nullable = true)\n",
      " |    |    |    |-- answer: string (nullable = true)\n",
      " |    |    |    |-- options: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- question: string (nullable = true)\n",
      " |    |-- sport: struct (nullable = true)\n",
      " |    |    |-- q1: struct (nullable = true)\n",
      " |    |    |    |-- answer: string (nullable = true)\n",
      " |    |    |    |-- options: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- question: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                quiz|\n",
      "+--------------------+\n",
      "|[[[12, [10, 11, 1...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| q1|\n",
      "+---+\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(explode(\"quiz.maths.q1.options\").alias(\"q1\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.withColumn(\"subject\", functions.lit(\"maths\")) \\\n",
    "         .withColumn('q1 options', explode(\"quiz.maths.q1.options\").alias(\"q1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|subject|q1 options|\n",
      "+-------+----------+\n",
      "|  maths|        10|\n",
      "|  maths|        11|\n",
      "|  maths|        12|\n",
      "|  maths|        13|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(\"subject\",\"q1 options\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
